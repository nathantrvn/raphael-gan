{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genesis of Raphaël\n",
    "\n",
    "Unleashing the power of DCNN to create random Raphaëls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, SpatialDropout2D, Conv2DTranspose, UpSampling2D\n",
    "from tensorflow.keras.layers import Dropout, Input, Dense, Flatten, Reshape, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_size):    \n",
    "    generator = Sequential([\n",
    "        # (latent_size)\n",
    "        Input(shape=(latent_size,), name=\"LatentNoise\"),\n",
    "        Dense(16*16*128, activation=\"relu\"),\n",
    "        # (16, 16, 384)\n",
    "        Reshape((16, 16, 128)),\n",
    "        # (32, 32, 192)\n",
    "        UpSampling2D(),\n",
    "        Conv2DTranspose(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "        Conv2DTranspose(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        # (64, 64, 96)\n",
    "        UpSampling2D(),\n",
    "        Conv2DTranspose(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        Conv2DTranspose(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        # (128, 128, 3)\n",
    "        UpSampling2D(),\n",
    "        Conv2DTranspose(3, 3, padding=\"same\", activation=\"sigmoid\"),\n",
    "        Conv2DTranspose(3, 3, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ], name=\"generator\")\n",
    "    \n",
    "    return generator\n",
    "\n",
    "def build_discriminator():\n",
    "    \n",
    "    discriminator = Sequential([\n",
    "        # (128, 128, 3)\n",
    "        Input(shape=(128, 128, 3), name=\"InputImages\"),\n",
    "        Conv2D(32, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        Conv2D(32, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(64, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        Conv2D(64, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(128, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        Conv2D(128, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        MaxPooling2D(),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation=\"sigmoid\")        \n",
    "    ], name=\"discriminator\")\n",
    "    \n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 4,481,569\n",
      "Trainable params: 4,481,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32768)             3309568   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_8 (Conv2DTr (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_9 (Conv2DTr (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_10 (Conv2DT (None, 128, 128, 3)       867       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_11 (Conv2DT (None, 128, 128, 3)       84        \n",
      "=================================================================\n",
      "Total params: 3,449,335\n",
      "Trainable params: 3,449,143\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_combined(discriminator, generator, latent_size):\n",
    "    noise = Input(shape=(latent_size, ), name=\"noise\")\n",
    "    fake_raph = generator(noise)\n",
    "    discriminator.trainable = False\n",
    "    validation = discriminator(fake_raph)\n",
    "    return Model(noise, validation, name=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = build_combined(discriminator, generator, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"combined\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "noise (InputLayer)           [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "generator (Sequential)       (None, 128, 128, 3)       3449335   \n",
      "_________________________________________________________________\n",
      "discriminator (Sequential)   (None, 1)                 4481569   \n",
      "=================================================================\n",
      "Total params: 7,930,904\n",
      "Trainable params: 3,449,143\n",
      "Non-trainable params: 4,481,761\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.0001, decay=1e-7)\n",
    "\n",
    "discriminator.trainable = True\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "combined.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(size=(1, 100))\n",
    "rand_img = generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7efbd40f5128>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD7CAYAAABqkiE2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO19bewuR3Xf78SOIQb8BpFrbFSMYqVyo7agK2pEFSGcNIQiTCWEjFDjpK7cVrQloVJil0qoHyKFNEpCpJb0CkjcivJSQmsL0VLXIYr6AZdLoGBsCDdQ4Fo2hgbbDa5SDKcfnt1n5+XMmTOzu89/L8/5XT33vzs7c86Z2dnzNvM8S8wMh8NxvPiBkxbA4XCcLFwJOBxHDlcCDseRw5WAw3HkcCXgcBw5XAk4HEeO1ZQAEb2CiL5ARGeJ6Pa1+DgcjnmgNfYJENEFAP4YwE8COAfgEwBez8wPLM7M4XDMwoUr0X0xgLPM/CUAIKL3AbgJgKgEnvGsZ/Llz342+AcIqUqi4S8nx+G1FKXrkrojof5Jb5/S5Cj1uQVL9m+t8WulFcqxFqzzz4JDzTEC8N3v7rh9/atf/SYz/3BaZy0lcDWArwXn5wD89Ug4otsA3AYAl11xBd70z2/H/7346a4E4Eqgh5YrARkE4NuPfQcA8Ktv/PtfkeqspQSqYObTAE4DwHOvewH/2V94FuhZF+f1kr81EAFphKPdrLDq96QGAi1p0qsTIrnIwonCEgwKeK0zfTSqWj/F8atBIZI+aCw83dJYW0dlzgOc35d1sZQyvfSp76p11lICDwF4XnB+zVDWDekhEbX/SneGCsfS+SjGNKFJoNEiqK5mQkq2yZ3bWcnyWvppo657dCCASsOx0v0U+6lp4u9jrLU68AkA1xHRtUR0EYCbAdy9Ei+HwzEDq3gCzPwUEf0jAB8FcAGAdzPz52bRxKSoNatcamvCgpaAQmKJDxr6BaN7X3Nx0zBA9ILMoVC5c9bQSYNUr91dn0ZpKtOplHIT0liFZRbZlsjFtKI0HdtzL7r0q+UEmPkjAD6yFn2Hw7EMTiwx2IPSykEKfdUg0aNERpXakqfe/SmGuRx6Nblet3ASY+sDxM/L0CvbMgpqjSXy/cxLp9g+pislYsP6bPQA9XEQ+pRONbW9HUvfD9827HAcOc4bT2CJcH0XB7YtEjVr76BBKeMtxba1PrVm5tfCEnsBKDnSlz2NnCg/ieYMl3MvoytAgiT1/FM561Jc8ehA77hb6p83SiDEnImer7dTRpDiillLkao8u5rkal3DXmsVS5NjLs/xsc/LZhE0VCtv9WlNNMeQR+skEokSY4si8nDA4ThynJeeQAht6WfJbaxdaBSg1XosaW2sy3pzl2TF5GyN/uyOCsm6MLW66AQZfB3BBNNKvLTxsewwdU/A4ThynJeegGpphD06ukmbLIJqhXo0uHVD/oIoJba6NpakA8JtlCS6UvItY5G0yr7tHm4zNiUuwkkRrNcJgmjjpzskrJ6mYvRCFFscUPt9Oi+VwCLPz34SVe6MeQ8B5UWz6dpgUopz+O2fmzYi8YQN2oYPotAmrC3u8Y+3UhoQ3J/K7W4Jd7RUYHzGccMq9569meXEZw0eDjgcR47z0hMYUXWNKPkbXVOzKR0YtX3AzLIRf4ENEKr9EAolF5clYVfIqNZ276XnkdEXxsruncTWOKQV0mjpsrwvUR1RGfsmNu7y/W73AEa4J+BwHDnOa0+gCkU5RtZwmR0wyXHFxAspBGoNCU0oWyYxbgVl1nXfspBMK3EsXxMzjsX6aoLXjGRwOfxOQnmMOKijpzTTnuWDVUwuzvQAYxLtG7HOeyUgpUNKIUJ9QklUOpM1sa8dkxKklORecudgjdYkqrZ1tj92kfkvkK3srE/iDcoR17DMBV2ufqddxxx6Hg44HEeO894TSMFAUS1Ky9zywk6blRFrRyGC5AQ37ppTENvncutmK5RVbLfcS1i89aKk8tIdS4InK5tSYq7HP1lijHq9SMA9AYfj6PF94wlE1nBU42nGL9yvkkR5ZeS6ffrh0MC27g/DVFILpqxAe9wopbjq9KvY59BsY6WtespJyCYxZtXJEn6FFdwsZyQkfaVlzjnbfEr32+olRDwHr3M/vw0CuSfgcBw5vm88AQmUBXbyQopo2RX9LIXKJFkJm5S7dgtvzJEsiPRTZshKtHUKbjZ5s+Nd1VzbYW0ieQxq5dJ9L7TTVrPmrXeMhe2Dc54qAX0mTjeyvvSzO07rSc5a6frQfh+ChKWKGy0mKOemwPo1SbhEmF9T9jlwXqShORFWcNuXgLQIrKVVTXsBhVhBVshtsN/ZNAldb+nhgMNx5DhPPYFW565cv3Sl1/rEGnguFUk66VqfB2BPYuU8rbssF45yitA3M9q2OmoWW1oOlH+mOA0t8xpLY07SFXBPwOE4epynnkDNwjdEUCTUblSmO5s/LL+NS0bhZpRWj2DfvVq0Wk58ami2FftlMJtFDbFWPL8krHdJ73ne2n732zYn57mJeT5GtydARM8joo8R0QNE9DkietNQfgUR3UNEXxz+Xj5LQhGMpZwrHkmFn0UIz2wbL/5KhVoDtVaQ1I44pB+JgjZclmtrQurDuGpugSZ3iTaBE9c/72lYotFIxz091pVJvUYJc8KBpwD8U2a+HsANAN5IRNcDuB3Avcx8HYB7h3OHw7FRdCsBZn6Ymf9oOP4/AB4EcDWAmwDcOVS7E8Br5gqZoV/pmci2ki7W1zyMPSOLK9JuU1utsu4ITVek8UnbSeMYn9d9jiUQWnEr9hKprlFZbhr+ycuIYdp4qNMRKeb3SRjphuFdJDFIRM8H8EIA9wG4kpkfHi49AuDKQpvbiOgMEZ158vEnlhDD4XB0YLYSIKJnAvg9AD/PzNHTzMxF48LMp5n5FDOfuvjSS+aK0Y317RGw190cfoZiiXvmJbQLrBkyLSdQK7PwaofeqjefYI+jg8/wJ/d9aJftpdAWl7w2BogF8sES65hL4Pb+mcaZafjU6c1SAkT0g9gpgPcw84eG4q8T0VXD9asAPDqHh4Tw+Qn7eqg16UyOWa0FKqOiCCHe+TYJ9Mmzviqc+LS3mCuZlUacoqO4nTjcab1Ri1B+i8XvJ8/v39x5P2d1gAC8C8CDzPzrwaW7AdwyHN8C4K5+8RwOx9qYs0/gpQD+DoDPEtGnh7J/BuBXAHyAiG4F8BUAr5snYhmHtvwpWrV3mjyrEh4aFAxI828SytVIOcvLamnLEo3DeBl1SFJIfbJLGy7+TefymFleCmaRgSrX29CtBJj5vyty3NhL1+FwHBab3zEoZxWHv1SqsBLfhGWo+60WplQnoiut31XaWvmE9Xdyt1DJnJSKXAJNkQ1PXo+Bz3I+xWi1W0ewfr03kdnbNoedin93wOE4cmzeE1CxYlKgZBtqlql0nLbVjL21Wy0WsRbrt0KKeU0WtbJ758QzB8XBr2VGWjHG9W15gr4R0jlsSgmE8+Okk36lZNfSD848akuO0kojbtQLY700FFpXKbRQb39UNYMhPfqaYZg3DnprDwccjiPHpjyBJbS+5m1KnkapriZLWyrNRr9P6y/pNy1Iq9IBW1JxLYT9XI9bKRGblqGjngjll7VrcE/A4ThybMoTWAoWSyOdn2RSSk60aVg6hu+nl21a0oNhweSRUG3adLOEvZZoiHRbMsIKSpa+ZW421ZoxHTarBCzrxLV+z3FwtV1wkiu/hgLRXErpV37WXVNPeEhbAIzLIcTx49ezMmKBrDykhFywXyC7vKyy1YZIgumeUjovgJafHvdwwOE4cmzWE5DQu9Zt9QgsbqdknQ8RRkhhzKGXUyOe+8Gi6Dog7HhUKQLxCJa9m96wQPY0rEus64zyHGqasyK/60Ln5p6Aw3Hk2JQn0GPdWqyDpPulMlaMxInvaGvE2olPKr3ZM+NYvlPiG45WR57JqS0vj9jOHJielskhS54gw9BuSgmEsKznWx067QaKimfWnOzfF7jOoxC46+PbhWcw0sKSjCVLV2uprpPdK5obCX1nX69CsBm7mkrirKTWUoKHAw7HkWNTnsDSX3KRUPMs+tH6dZ66xbPuE9Ds6P6lKNJFlaoRwqpa7JkKO9ky56DsiK+1/DpRDxF+BWpdj6SVenQf84vV1hrcE3A4jhyb8gR6YF3OOzho/9+EygaOJSxe73cSejwAE9LfRpO8A2UrVr6dqMBGEa3sKZU70ZqYrlMso5T/4oIfFKQDO7jlcE/A4ThynFeegKadJfuhLQjO38OdbpNVsg2GLZw9W6BbNkq1wJS5DrubdD2S0SRAmZM1JxCKYZ8n5flhGQPr6lRdDrnM6gVFW7I7ZDmvlIDUQXmISjdy4QBhXIoNXH/bTWiXY+3QJhyrJl7Cdrx43MfC8t1YKvE3n07e89ri5ZL7CfNwoGXO98PDAYfjyLE5T6Ck5aqul6KyawmxXs26VGIGqC3zSbzbwMhdc5GGsgFQ5knZ8pVo4XmqP+5WIoMdbRlh3bPQAqq+cE0rE6KkZpTaWTbSyVLJcE/A4ThybM4TGGHZbBpdT+JRsY5wfdaGVTLqYoPB0WSTbFdpV74lmRca5fRazark9yXftKTlaeLD+dGtjUItDVefBa1JwJ6etSZ6xfqUHtQlWeKtxBcQ0aeI6MPD+bVEdB8RnSWi9xPRRU30MG83HyufxWElrNQLL5WqEcrjgso1ide+fuPgWO+LJs/S94aEzyx0EtPkmPq5XPgY0o0EkK5VsEQ48CYADwbnbwPwG8z8IwC+BeDWBXg4HI6VMPfV5NcA+FsA3jmcE4CXA/jgUOVOAK+Zw2NpSBqy2xrt31cf0uLBRS7bOasF1LwEkcYCFkyvRAub3QnrenAStQK38Q8j2t5hvVc1ubV6rf2VbkFOo36T5noCvwngFwF8bzh/NoDHmPmp4fwcgKulhkR0GxGdIaIzTz7+xEwxHA5HL7qVABG9CsCjzPzJnvbMfJqZTzHzqYsvvcTGE/ON0DIGbKAiqG4a/pWuhzKkfUlls2l6gGn4lCXtG7esQZtdnmPlloU0CjR5csZB0u6ZbYzLKdMoV9ODgQglnx1LnfKc1YGXAng1Eb0SwNMBXALg7QAuI6ILB2/gGgAPzeDhcDhWRrcnwMx3MPM1zPx8ADcD+H1mfgOAjwF47VDtFgB3zZYy5Q3dqrRq1NneQRI7MoCWn3weZSjJU6TUsGRQ8hLkBiX7ljNb27ovk3Yo5AKUiSR5ZS2yySOm90bLizTnEPYC1LMra2wW+iUAbyais9jlCN61NIPaQ9uamNHqy48Cg9KW09O/+8yYvXvKg5svzigr/cqzvechpSE5+QQpz5GA7QtC/Yp2uQShFLuNPrPAbz8uU7lEcUlYVK80hvEcSftUH/VFNgsx8x8A+IPh+EsAXrwEXYfDsT42u2PQApPLPJN6+gppWa/ydIUpKOmUSmQyFmpavrymtXu7Ti5Pk3XmUIr+JGEvRhrLhAg2gpPchGV6kd8zS3/K826QbJh3JLpmOgf/7oDDceTYvCewuPY3gYo2NrD5kW2evklH0bVe/jL3BsKaN7En12/ZajkZS9te7m0Rb3zPVIKBsZfrx5IvNSct46B5vZxWaMTmlcBhUM/h1jLB+fEMd5lT1TdRpfQ5NjM43Cp9u0O6LkJHPlbcCeblcxX+U4iYa0ApzChLIYZh+4R0Gr4g5FyEhwMOx5FjU55A1W1TIC6dzKLRa8mDZE2i9Zfw5MPTlKcoUIXpmuHWnPupoZXmMj7QfCr7lVhU7p1Ko3Wm1++CewIOx5FjU55ALdnUagGU9BqE4EyFbjHz0jRCS8/SFtoSULnjcYIqPKPc5Kiw2qNey17zOErltU06J+MVtEJbmi3NndJVCdry5YE2C20d0qDKk7LuHIfKKKyd/s5ebVVZSgWVuO94ppIy0t/ooyBBZIWmKOdm8Ws73UL6pb63pc0memE9bWxLbfOK028p5pVr0Fz4fMRVg9Clhj0x6HA4FGzKE6i5/K3rqWmZbHFK9mo4Tl7nXbZaiRsuCFxd6y1ckyAniNaB1SPQluFaQ6FWXrU6snfVhnxvX7ogV5OkzqFMrSZt/3xwT8DhOHJsyhOoxdEWSO1Dq5/v59db2OWZF4vHpUlaUUxElD2OPilyIkvs6JubT6glBi30rVa/Xdb5MzaWzerX6FRa4Z6Aw3Hk2JQnEGJuZrpOuXyJg+2jkxw2fR1WMtXj4klAihK3QK1eZKMvRu2Z5bucjFjjnpV9leW5yXZduIvBvWjxMKwrRiR2er0c0GaVwBqIQ4HyzaVamWXildYS9wcaDW2pKNBUjbAtMtlSXHog0Utd56nTLY8pC5fscpS5W2mY6+kbWwQsowA9HHA4jhyb9QREHWdZb+Jc70qvytK0aD3NEi8fiqYGk7HWf4JL6lQtCdSOslehbYApm6blwzRFjD3yXoTf0MtfcCos2zYLoocdLVt4pHnFYevm/UCWkKjed/cEHI4jx6Y8gdLmkqhCAzQLoG9eyS2eSMsoT1ptXopnGiF9cTPmXeepJT6TJcuklbRJqISSNbRsINIgbdzaS9LjCCSJWMnX67G/qijWQWjqT30kN6UEquI2/qKG5QFo3zUmta04r+JclB41LSGoQVcMI2/5Ia2vGaQrJSXuGpa5Bxa1tw7WC38m80LNTLQQ0k7MwwGH48ixKU8ghOjW1raPFdpGVRVFKa3TTtpZSjK1ad3Yc8h9v3YXWPIfY1mad+8pq5fqqmfYTBy/dTD6PiRLItTHUF8vWxZzFmUtLWt3WefgnoDDceTYrCcwQtqTJdpfoTDTiSQcs3BZXSaLpdNQitIoOtPQvnFnNjg/qdmZdYy9zctSN1QZE8NaWS9ih6psnUldkC5J1Br36/VmeQJEdBkRfZCIPk9EDxLRS4joCiK6h4i+OPy9fBYP8PDB/hNfk0OH7DnOxlkqFCuWqDbX0qjr1KTPNDYaxHEjGj7TxfEFvWkbqX0qYcZM6EE7Wlumqor3M2d8Y3NpRajWx17oYzjKqNxhkmY/Yc6oSpgbDrwdwH9h5r8E4K8CeBDA7QDuZebrANw7nDscjo2iWwkQ0aUAfhzDC0eZ+f8x82MAbgJw51DtTgCvmSukIsV0xMMH4YeGhFFZJ4evFo00bINpSC3MqKtbrItu85fBfjz2LxlF8B77XVn2otUWpM0alnKnz2j5ejBSGd2b4TA8Hj653zD5Vz2+gX3EhLlYmKIcVl9lRuwwxxO4FsA3APwOEX2KiN5JRM8AcCUzPzzUeQTAlVJjIrqNiM4Q0ZknH39ihhgOh2MO5iiBCwG8CMA7mPmFAL6NxPVn5qLqYubTzHyKmU9dfOklM8SYj9xjAHJLUPIo5KW9HltWskFm3T9avbB1WWx74N+KdQyWHdnruZNscSJbOd/U3omQvDwMgp8neVAKEYnunCGfowTOATjHzPcN5x/ETil8nYiuAoDh76MzeDgcjpXRrQSY+REAXyOiHx2KbgTwAIC7AdwylN0C4K5ZEi6Afb5A+gAwReGRqVgnateoamVM2H/ZbX8cpvszun1p/B6HQV1ZCORWK459UeqE4yDmeFKBCnRSD0CtLlycvMqSR2dwvQSHlInA+tdR9zxaZ+fcfQL/GMB7iOgiAF8C8HPYKZYPENGtAL4C4HVWYmNKZzkEST7EA7J34ks/ziE9cSOtzl/esbBpgW2sKrVWdttT8tHwhYUl7JNiOgjSrRwIE09MwzCB8vsY3maENIsy2mcsqZwK2Fcb1VpMxSaNzmOWEmDmTwM4JVy6cQ5dh8NxOGxqx6Cur2I7npcrqbTAIdjnW8b3CbSJ2GQ5M6uSnC+H0EqszasTgje2hzamDe5hsRoHDv7eI5j4cuQRjAFi7EXWeced2C/v7U+Uejrh+ICmY5aeiamjNcp7+HcHHI4jx6Y8AUnp6xZtRkDL4Z8xkSMtK0mc2/hK6YUlLPRk1HJqkk+w5Bg2Z0Xm5B4WzFvocpNwvHcXksTwrk7pW5JSKkOO5xmV35/LwbEXy8H/cgf1AdyUEqhBSjKVr1rnTn4DuPjALIcl5vV+ApKuKvUrM2UQyub1LZrSM+UOs/wxJeIs57bLwqdlIa0wlADAjb/4XNp3kL7Mtt7rOBzQU4V1eDjgcBw5NucJaBZA8nR6NeBEK7f7i7nqKyy/9bvfUXaqkVgNMcF53kEpIIxL2u5RZeGMtLLR6tp4av0stW/6rgTnnoP4PAgroiW4J+BwHDk25wnYsNwmnfKbawo+idHCW98XqtkAPXlVWjIdriZJw+jdC0FSVLO7S+YRJqlDv2vlnUpVPtq6ZVzFuGepungt1ddzC3EeoijGjJvlnoDDceTYnCfQsqM0vB5qXYt9abVG4U5hE8+gUKvPgmWn5G/cVpA3etURR0UpzVqZBjkubkt+1L+ZdyjvwIiKOS9tCGuB3paTi4IgFJZLeZkVtw0vjR6PRlqD72lXvRq594ZbbgwHeiE/kPZFplZe6fEiyVORlu1xssihhTZhaq2SNtzVrCwHalc1WZefG+3qyMMBh+PIsSlPoBXradHDId8oUqqnnYub1GN0DJbURPM+rDR1i6hZZ63dMvVKLSj4P/QjysMsjZQgRcU90MZ7+jbmVKtnBrsn4HAcOc4rTyDVo/WUVGt8JEVvWlkb9Rr6/RBlzS8inm+0nrbD5xG05KW0xOKlEZPyOOmdsnkh9jucvrZ8t1TZeuck76AkT+lmtCwK6zN8v9RLpYStRDPH5pRAaZJJE0WqFw5c+fWcUu10F2GZQwrrVKqtF7dCzkzXd+/FPKWJLU/2OcouoiHcXAvtfv6qZuymrM3D+PG1qVFKRr9475LtDfoLTOrwcMDhOHJsyhMw7JtqomJrE7qFcfqnRr9Oue9aL3a72pLNCbZWBeQeQequNy/R1TxkYW+F1SuUCcb1tDxczz0pu+FhyWjhJ8k1+YVfPYux5Dot3BNwOI4em/IEQhxu31gtXmvLK5Qop1R7UedT5qLyj6yPffSt0Wh/Ci4fXRKO5VSttLsuCair/AUSetOgXk7FlCoUmccpx7S6nuTUO7tZJbBEMupQ2KKM05eERv+65Agn5eGvbUh0g5bLQXpYQ0aGfRBR/j9JikrdDM4p+PljSzI5BO/de209I0/S6qbHYlJsVy0Ky8MBh+PIsVlPwJbwyWvNWyzpQ32/Qh0cWaakrEq8nNCc3q+QVRdJE4JFZ2W/fPcYN8YPpaqyrZQc5QIVBvKfZTN9KyQZSo1n2aJHQ9zrXlk3U1TgnoDDceTYlCcgbdwZYVWY5R8J2TiCDmZv6KmASmZ+T3jcITcWlc1smBes+13GRFfWVumgoe91/2Tqc5FklF3cJ1AKlDQuac162jJDzj6jpK0KijO+4S1ZszwBIvoFIvocEd1PRO8loqcT0bVEdB8RnSWi9w+vKHM4HBtFtxIgoqsB/BMAp5j5xwBcAOBmAG8D8BvM/CMAvgXg1ia60IwBQ9+saaOyNOaEclGPuPBB3iMSyiQi6YilGF/ASTx+yqNXt/BWCB1UauaF0khM5KYXzu76FPMsS1EY+iLkGWZpaYdEjZJPcUXR+AjMzQlcCOCHiOhCABcDeBjAy7F7TTkA3AngNVZi1rXZwz7idZQfSHvb9epPb8m1wfoI5C3s19JpbGMw0QpOmIdPhVr0CuSGDliFK5ZzVNLLMuybqqhGRYj47coa5rya/CEAvwbgq9g9/I8D+CSAx5j5qaHaOQBXS+2J6DYiOkNEZ558/IleMRwOx0zMCQcuB3ATgGsBPBfAMwC8wtqemU8z8ylmPnXxpZdIHFC3EttIADJgEjfU3C1up1S/ZlV0uofzpXKbT3t3PeyMJtFkxCXvYXdO6mgG15b11iuIZZ0z4muKPScc+AkAX2bmbzDzdwB8CMBLAVw2hAcAcA2Ah2bK6HA4VsQcJfBVADcQ0cVERABuBPAAgI8BeO1Q5xYAdzVRJQKIJu0vmohQLzbGlwIliWobaB+aHg6kyivZywwF49lCt4bUewnj1Oa7tqQ5bE99zGDS31osszrJRtZzcgL3YZcA/CMAnx1onQbwSwDeTERnATwbwLusNHeZzt2/yXvbpTjyhz3MjbY5wylPoXdFGhLVUMKU9pykoYSJVj4qMmxjYXGmNXna+pcHNqqU+4vz7vVSkMK69FpJol5pB9sYfwUkGHhK/rVg1mYhZn4rgLcmxV8C8OI5dB0Ox+GwqR2DALIXKMYudhgChOfp8WwpEFqokKPapCDGGnbKvjMyFEzeVZDW1qhKdthid9Q6pFCJGJZ3L8Q/Cadh/t0Iv6+o8ZTmjjJN1EqcXQxKCbNiUf/ugMNx5NicJ5CCxLN1YsCJl5YLIFi/c67F0c09CDbFjVJUGUkEDKVSbiM9bvXBwjrqXVSJpcnglgW4nHAqByG33rW+lT3FfDaFM0fyzzJeBOhfJJGuyVkrDZtXAjIqt4iUeiY/LKwo0Eh/oIORuWPag96rAMKTUoLSAnOIYxCpRx2XH8cS4TKXuC+tj3COsgKcHmHr+OmKgYPj+Gr4/a79D6TsKwlco+8jt8PDAYfjyHGeeQKtNsxqQbT6bdYkdp1jiyS5nSYUFH1LIiz3U8qOo2WU59vYyXPhqiXLLftSS652WpUkYCai1KfoC90Ia0ZN9+t+PBGmvH7k8KqvodbvlnsCDseRY3OegKaztBhLoyCuMtVMWZZXmM72mpglKyu1EzyCAv1dBYtWb/MnSkmv3Fa1LfnV0lBiIlOqT6NXkCb8grhY4amnKrtSsQryNOf0yrZc/poc+T3I54nmo0Y/CTeWNnTXPQGH48ixOU9gwhI57Pnc1fLANOlSWixZSFeqqS3m2dR+umhVkrll5Be5OxT0QHTu5nEJNxKJfDgv0ukN9Wk60+U3Et6TmHI26ea5pKLAo31lZMNKYIQ2JQvOa9Ik+1HZGqhWeXRd28iG5KU0ky3cCUWY7+JqFGzDps96UzKtUrO8bFegm7josUSlAlnl1scgdv/1O1K6mrQOc4GZm1/pvao1ZHg44HAcOc4DT6AV4VqKohW7Pcwe61teHjupcGeSY4d+n6Jtg9I8rtKYzV/WbYW+rBwsv5o9xYSG5GJKS4/7xCuSIYEAABE8SURBVLSw8BitWeoSuCfgcBw5NucJlGKx+jLcCMUKREpRULMBU2nprMRC1rVh6TzLFMWqwbLkGhtmZLsaxL1pjAoKPK5yQlOmP8Xu/SOkJVGX2NI0wZI/2dOZc8sbxZf3BWlLpjE2pwR0WPPVsosm3xnOqu1K2+5i7qhK+wTyFnG7hApL18oUl4BMN+Cd7WCrTbZU7nCNQmorqN/eJzPimzeTnrW2ZKhARZQnL9wr1nBOmrc3pIW5SdBflBrDwwGH48ixOU9AX0Tp87HCHWeasg3fRlXyyErKudkyNy0vrpvoMsO4pFeXd7wf+SinexmiQ6Ob3Lq/YVbQltxHuwc5LTNn/AV3pL4sqtX0xKDD4VCwOU+grJVr9teggWvZtCgnYCdLypm1VVRUyW22cGmFOkQMIa9SDFwLJFi1mpb+cZi4NcTMdiuqo7wMJ9WqUS3X21+ppENU2RqwOSUwwu4mN3S/4F5JE6p0i0qpr3CrZ0pfnxDCuoKQx1zj4Z+3wtDmRMvpQ6PKT3KRtcx7Y/Sg0pDO45AlNQE6N+svIcZ8LOifIR4OOBxHjs16As0INlFlujBecYuOa3rTrlfTZFfKUW9Xq76W+29gXWiwwMo+Bwnb0Acu1FfF6ZZGhpS05ORvXS4p8RlLygq9Pk9tzFSOk75OwT0Bh+PIcd57AunyXlhWLoD8bd3xWpWrpLMVZo0Q+QeeTrGOET0ekdh4Af778ya6urfQK+JyXmGppbb4LN+L9khfcHsrqHoCRPRuInqUiO4Pyq4gonuI6IvD38uHciKi3yKis0T0GSJ6kV0Uh8NxErCEA7+L/JXjtwO4l5mvA3DvcA4APw3guuFzG4B3LCOmhjGqouwzHo1INaxkkWQbE35s0szC+O7ugO2ebnAu8e7niaB7+Vha+9/MygDrmKb1Wu8FI2wTt+aspJUiJ2X1VmXZWu5PXfKqEmDmPwTwp0nxTQDuHI7vBPCaoPzf8g4fx+415VfVeIh8UXaypW4xMTh96b3KgAGWbnfKY/+K1MptlBVPD/aijQc86YWQeUNvBUkHOTVNmXGQuWg17Mq2Lq+G5RKDO268/9Tkt/RmOQUqkiXIE8SI3sTglcz88HD8CIArh+OrAXwtqHduKMtARLcR0RkiOvPk4090iuFwOOZi9uoA79Z5mhUxM59m5lPMfOriSy/JrqsGyspDEEx6hbPkUOWO1mgXJsqxe5bbhxYZa5tIel1iGVpPYTJcFpuzlHXe8yIUV7xqAYt0TZpjUlBJ0VHo7VnDpEWCxEBK7TJBfEuRgl4l8PXRzR/+PjqUPwTgeUG9a4Yyh8OxUfQqgbsB3DIc3wLgrqD8Z4ZVghsAPB6EDU2QolFVn0aZsxLW2XIzWvLUmqdlel84K+uL8GReIij1cNp5LpsyrDAZwJTLOGesYvLyrCPhGqvJlRySvHV50mutrep3qLpPgIjeC+BlAJ5DROcAvBXArwD4ABHdCuArAF43VP8IgFcCOAvgSQA/V6Nf5Juc229u/vPS0quf7NTKIKVW6XbUaPYg3t1WGjlBouibOMjqtcopudvtfR0d7TFpW7p3MWVpp2b60M1BaF/CMDInPF8OPcQKeird2o6OVpUAM7++cOlGoS4DeGO7GA6H46Sw2R2DS1rLSGE2mmPRrg6F4d53nXOZZm8/YytrsTVhudUzouyMM/OzxJ0q+wwkejcSdDlyaUt3IeFFxZPYO0jYW6VuhRwOaJzq98e/O+BwHDk26wn02hktFi+3SFN0Cn/RMiwd5SsYvZBZbGsN07h8Kp96bGBuTArsqgVxdnI0IrLX+2/J2QZB8gBackZiV7gsZV8+pA8MBqU/ANvA3D0Bh+PIsVlPwI7yOoKS+K4qyhYtvsvYrq33Qxcg5T/W6PCbkq8lEijgkVrnvExelbXJkW7Uaamfl+orNOlVs6XW0gUVImv4iTzyjfhIqzypFGVsTgkoC1qmQZWvDaU8OX4SffOk0HJHjZD7VKYYO7P2aSYnqqR2nJGt3ZN8GS84lzJmLSD5Ac5OKnSlhU/ph0PUsef0IIc0VjUR8yXt8bygZRIlrcMTgw6Ho4LNeQIlmzLPpbItypl5xR70IogsqkB4Mj79I6Fa1MlZUschD7ZYJzxnDbQqQ1i91bcr2WrN70nJTpZakzNOduY10xLteyTlFcuC3Ibxd0/A4ThybM4TKKG+ISeM9tNNPGsl7Zalq3oi4sU2/jYLP53YlluFTAPr11usLQXVxMhdHYJajw2+n+ruBX6RQqJ9lliXGa1+ko7zRglIiS1h/5ZasoT73kVjP9cqO7vK0UBAS3HDDSIIXItlel/DWnELqlLI75zlWeu/f2GMY+tdyls46UApAamms6tlKbW8oi63hwMOx5Fj855A63Kg5kLV9Xi4Bl5O+FgQBSQWS1b9IYi+pTZt8Uskwfmh3QL3jVadPidn+eKeWUaK70ncep3wbkTaC0t7NTRUqLX8roh7Ag7HkWPznkBdR8c15Hq1+CuNZcuobStZIwVpjgOVOuHi1+LIzM643tgWA9fA0VHotTU1buCx7DIwihTtOQH9AlLn0zRKG1QCY3ZsnEhRqQDrWnBaJiUSbW6hNqRysnLeVIoenxX2KHRBj22GP2Hycu6DLzOfF7KUU83S68K6Q5Cgfv5VbJ2OlNxWx2Q/QezSeTjgcBw5NugJDDAs3coOGxeOpbpxvfCbBelXZedZXk0Oza7kg7CoB9CYizReihi0hlitWPa+tFnlJaAFSYTc+6jJ0PNTeu4JOBxHju16AoYFLRLKy2k/rUZ6LV+CsiYEl7RMrdmOLnYZIcoOpYScyYqulImk6t1Yg6c1U5SmFksSlsfPavVNfTfcA/cEHI4jxwY9gXnmw7bVtXZVfx/Q9FNY+bKkfcvtlH8oyrG0JTUZTck9yHsY5uetPwveC8lCtmXqW+Qo96WVh30VaTnsx6NhEm1QCSwPq6tuuWnWfYSip61xqpC074gzkWtE3wJtzYe2yijVqz2SuSCtXCUayy1zpoZkLprmWgIPBxyOI8f3jScQp4rKqRh5E0iaYsztzHRNXvbaewo0leQeGef1RUmXwGBpgtevg+JrMWR7tfszbv4pcSlg8c4p3KqG2iKMzbtoW9TVqegeox1lmeoSVT0BIno3ET1KRPcHZf+SiD5PRJ8hov9IRJcF1+4gorNE9AUi+ilTDxwOx4nBEg78LoBXJGX3APgxZv4rAP4YwB0AQETXA7gZwF8e2vxrIrqgRSBWPhoo+JRbsEgzr00qz/FFo1odYp4+mF5NGm4ASeUuXZNliI8ZAFPIaSRCwhbSyqgOl4hp+j177JJN48d8Y8rkuyGOmdELmCG2SLVES5KRxBpt81yCTN+OqhJg5j8E8KdJ2X9l5qeG049j9wpyALgJwPuY+c+Z+cvYvZj0xVZh7AOQd1saRB7+xVekR62FZ1gyvq1+5zGHvxnCje+Ir3GWYJk0+zpUn5Y6NwOT5NOqyGXYp3irAcnriKpVoZDXrqFuqCyY88jnWCIx+HcB/Ofh+GoAXwuunRvKMhDRbUR0hojOPPn4EwuI4XA4ejArMUhEbwHwFID3tLZl5tMATgPAc697wV4l1vcJVmQqHE/0OLoWfkcgTtaRVJjQDNpyWqJJbutVyc0c/6bJIGZ9/TyjR4z8J8/CVFU8VkuhJSlq5x0GQXMkLqXY8nmitU6Px3bZPWuULm4lJGw7CHYrASL6WQCvAnAj8/6L4w8BeF5Q7ZqhzOFwbBRd4QARvQLALwJ4NTM/GVy6G8DNRPQ0IroWwHUA/sccAeWIMI/VrFGSlpibKFJT2GVN5smSTJ+Rf39fgvEY84FB5ozSDyNPWkZdnxd7ljIQ8xNztajfFs/r2ZHWbMaOSpgnSulKGYf66MZUSJJ4Zraz6gkQ0XsBvAzAc4joHIC3Yrca8DQA9wxvh/04M/8DZv4cEX0AwAPYhQlvZObvtgik9WNpt1RjkDmDg7/PHDp1ef2aOyhTL9NYDITA9Q9jGyGAyDufS2YUtjwGdpQc9B4aodxL0C0FiFS921KrtIU0uDbVoc/EGFUlwMyvF4rfpdT/ZQC/XKPrcDi2ge3vGAzeQz8ZpNHdarOZog6VDbskSHA0LvLkiTM5GalczTOKYnJPFzFooRqJnEqeKFXIS6ktyn+ULTpvdmvyDkwlOrHi1cjjGcumpKh0H+diN9e01G6tLC2fk/bUW/h3BxyOI8emPAFRX9lDm376wkpL3jaIo8XlQgtfwdyH55wXlarH6BwYhvCue47OcpQlSV/FZbFvgxiycAWUJFQ9ElEQDv8U6tREigvl152X66csdjVCGn1ebwvcE3A4jhyb8gQAKWNbypAeQoq8REyot2JG8Fmz08nbQNsItl3sRnaPKb+qWefa8GVOlpCcWG8GzaccW/0lJJ25OnAI0FPfxUX/+89Aj/15PxHrWK21zrjEWphDxgkoWxOsq3U1Ghp66Qd0n/6t76hVPRxwOI4cxK3u4xpCEH0DwLcBfPOkZQHwHLgcIVyOGOezHH+RmX84LdyEEgAAIjrDzKdcDpfD5TisHB4OOBxHDlcCDseRY0tK4PRJCzDA5YjhcsT4vpNjMzkBh8NxMtiSJ+BwOE4ArgQcjiPHJpQAEb1ieE/BWSK6/UA8n0dEHyOiB4joc0T0pqH8CiK6h4i+OPy9/EDyXEBEnyKiDw/n1xLRfcOYvJ+ILjqADJcR0QeHd0o8SEQvOYnxIKJfGO7J/UT0XiJ6+qHGo/CeDXEMaIffGmT6DBG9aGU51nnfBzOf6AfABQD+BMALAFwE4H8CuP4AfK8C8KLh+FnYvT/hegC/CuD2ofx2AG870Di8GcC/B/Dh4fwDAG4ejn8bwD88gAx3Avh7w/FFAC479Hhg9+vUXwbwQ8E4/OyhxgPAjwN4EYD7gzJxDAC8Ertf2iYANwC4b2U5/iaAC4fjtwVyXD88N08DcO3wPF1g5rX2xDJ09iUAPhqc3wHgjhOQ4y4APwngCwCuGsquAvCFA/C+BsC9AF4O4MPDpPpmcMOjMVpJhkuHh4+S8oOOB6afrb8Cu++2fBjATx1yPAA8P3n4xDEA8G8AvF6qt4YcybW/DeA9w3H0zAD4KICXWPlsIRwwv6tgLRDR8wG8EMB9AK5k5oeHS48AuPIAIvwmdj/c+r3h/NkAHuPpBS+HGJNrAXwDwO8MYck7iegZOPB4MPNDAH4NwFcBPAzgcQCfxOHHI0RpDE5y7na970PCFpTAiYKIngng9wD8PDNHb0HhnVpddQ2ViF4F4FFm/uSafAy4EDv38x3M/ELsvssR5WcONB6XY/cmq2sBPBfAM5C/Bu/EcIgxqGHO+z4kbEEJnNi7CojoB7FTAO9h5g8NxV8noquG61cBeHRlMV4K4NVE9L8AvA+7kODtAC4jovGr3ocYk3MAzjHzfcP5B7FTCocej58A8GVm/gYzfwfAh7Abo0OPR4jSGBx87gbv+3jDoJBmy7EFJfAJANcN2d+LsHuh6d1rM6Xdb6W/C8CDzPzrwaW7AdwyHN+CXa5gNTDzHcx8DTM/H7u+/z4zvwHAxwC89oByPALga0T0o0PRjdj9dPxBxwO7MOAGIrp4uEejHAcdjwSlMbgbwM8MqwQ3AHg8CBsWx2rv+1gzydOQAHkldtn5PwHwlgPx/BvYuXWfAfDp4fNK7OLxewF8EcB/A3DFAcfhZZhWB14w3MizAP4DgKcdgP9fA3BmGJP/BODykxgPAP8CwOcB3A/g32GX9T7IeAB4L3a5iO9g5x3dWhoD7BK4/2qYt58FcGplOc5iF/uP8/W3g/pvGeT4AoCfbuHl24YdjiPHFsIBh8NxgnAl4HAcOVwJOBxHDlcCDseRw5WAw3HkcCXgcBw5XAk4HEeO/w+SLK6vKtw6XgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(rand_img.reshape((128, 128, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_generator(data_path, batch_size):\n",
    "    indexes = np.random.choice(len(data_path), len(data_path), replace=False)\n",
    "    for batch_index in range(len(data_path) // batch_size):\n",
    "        index = indexes[batch_index*batch_size:batch_index*batch_size + batch_size]\n",
    "        batch = []\n",
    "        labels = np.ones(batch_size)\n",
    "        for i in index:\n",
    "            batch.append(np.load(data_path[i]))\n",
    "        yield np.array(batch), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_the_raph_growing(generator, epoch=None, save_path=None, size=(4, 4), noise=None):\n",
    "    if noise is None:\n",
    "        noise = np.random.normal(size=(size[0]*size[1], 100))\n",
    "    fake_imgs = generator.predict(noise)\n",
    "    fig = plt.figure(figsize=(size[0]*4, size[1]*3))\n",
    "    if not(epoch is None):\n",
    "        fig.suptitle(f\"Epoch {epoch}\", size=20, y=0.92)\n",
    "    for i, img in enumerate(fake_imgs):\n",
    "        axes = fig.add_subplot(size[0], size[1], i+1)\n",
    "        axes.set_axis_off()\n",
    "        axes.imshow(img)\n",
    "    if not(save_path is None):\n",
    "        fig.savefig(save_path)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/300 [00:00<?, ?example/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.027263202, 1.0]\n",
      "[0.021769606, 1.0]\n",
      "[0.011709269, 1.0]\n",
      "[0.005893571, 1.0]\n",
      "[0.0059382063, 1.0]\n",
      "[0.0009068118, 1.0]\n",
      "[0.00099529, 1.0]\n",
      "[0.002152055, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training:   0%|          | 0/3000 [00:00<?, ?epoch/s]\u001b[A\u001b[A\n",
      "Epoch 0 - disc training:   0%|          | 0/300 [00:01<?, ?example/s]\u001b[A\n",
      "Epoch 0 - disc training:  10%|█         | 30/300 [00:01<00:10, 26.80example/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0008913624, 1.0]\n",
      "[0.00050872046, 1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0 - disc training:  30%|███       | 90/300 [00:01<00:05, 36.89example/s]\u001b[A\n",
      "Epoch 0 - disc training:  50%|█████     | 150/300 [00:01<00:02, 50.10example/s]\u001b[A\n",
      "Epoch 0 - disc training:  70%|███████   | 210/300 [00:01<00:01, 66.83example/s]\u001b[A\n",
      "Epoch 0 - disc training:  90%|█████████ | 270/300 [00:01<00:00, 87.24example/s]\u001b[A\n",
      "Epoch 0 - disc training:   0%|          | 0/300 [00:00<00:03, 87.24example/s]  \u001b[A\n",
      "Epoch 0 - gen training:   0%|          | 0/300 [00:00<00:03, 87.24example/s] \u001b[A\n",
      "Epoch 0 - gen training:  10%|█         | 30/300 [00:00<00:02, 109.56example/s]\u001b[A\n",
      "Epoch 0 - gen training:  30%|███       | 90/300 [00:00<00:01, 139.05example/s]\u001b[A\n",
      "Epoch 0 - gen training:  50%|█████     | 150/300 [00:00<00:00, 171.39example/s]\u001b[A\n",
      "Epoch 0 - gen training:  70%|███████   | 210/300 [00:00<00:00, 204.58example/s]\u001b[A\n",
      "Epoch 0 - gen training:  90%|█████████ | 270/300 [00:00<00:00, 236.60example/s]\u001b[A\n",
      "Epoch 0 - gen training:   0%|          | 0/300 [00:00<00:01, 236.60example/s]  \u001b[A\n",
      "\n",
      "Training:   0%|          | 1/3000 [00:02<2:11:07,  2.62s/epoch]\u001b[A\u001b[A\n",
      "Epoch 1 - disc training:   0%|          | 0/300 [00:00<00:01, 236.60example/s]\u001b[A\n",
      "Epoch 1 - disc training:  20%|██        | 60/300 [00:00<00:01, 125.69example/s]\u001b[A\n",
      "Epoch 1 - disc training:  40%|████      | 120/300 [00:01<00:01, 152.51example/s]\u001b[A\n",
      "Epoch 1 - disc training:  60%|██████    | 180/300 [00:01<00:00, 179.13example/s]\u001b[A\n",
      "Epoch 1 - disc training:  80%|████████  | 240/300 [00:01<00:00, 204.20example/s]\u001b[A\n",
      "Epoch 1 - disc training: 100%|██████████| 300/300 [00:01<00:00, 226.38example/s]\u001b[A\n",
      "Epoch 1 - disc training:   0%|          | 0/300 [00:00<00:01, 226.38example/s]  \u001b[A\n",
      "Epoch 1 - gen training:   0%|          | 0/300 [00:00<00:01, 226.38example/s] \u001b[A\n",
      "Epoch 1 - gen training:  20%|██        | 60/300 [00:00<00:00, 255.76example/s]\u001b[A\n",
      "Epoch 1 - gen training:  40%|████      | 120/300 [00:00<00:00, 281.98example/s]\u001b[A\n",
      "Epoch 1 - gen training:  60%|██████    | 180/300 [00:00<00:00, 304.87example/s]\u001b[A\n",
      "Epoch 1 - gen training:  80%|████████  | 240/300 [00:00<00:00, 322.11example/s]\u001b[A\n",
      "Epoch 1 - gen training: 100%|██████████| 300/300 [00:00<00:00, 335.11example/s]\u001b[A\n",
      "Epoch 1 - gen training:   0%|          | 0/300 [00:00<00:00, 335.11example/s]  \u001b[A\n",
      "\n",
      "Training:   0%|          | 2/3000 [00:04<1:58:46,  2.38s/epoch]\u001b[A\u001b[A\n",
      "Epoch 2 - disc training:   0%|          | 0/300 [00:00<00:00, 335.11example/s]\u001b[A\n",
      "Epoch 2 - disc training:  20%|██        | 60/300 [00:00<00:00, 324.09example/s]\u001b[A\n",
      "Epoch 2 - disc training:  40%|████      | 120/300 [00:00<00:00, 317.11example/s]\u001b[A\n",
      "Epoch 2 - disc training:  60%|██████    | 180/300 [00:00<00:00, 311.31example/s]\u001b[A\n",
      "Epoch 2 - disc training:  80%|████████  | 240/300 [00:00<00:00, 307.63example/s]\u001b[A\n",
      "Epoch 2 - disc training: 100%|██████████| 300/300 [00:00<00:00, 305.64example/s]\u001b[A\n",
      "Epoch 2 - disc training:   0%|          | 0/300 [00:00<00:00, 305.64example/s]  \u001b[A\n",
      "Epoch 2 - gen training:   0%|          | 0/300 [00:00<00:00, 305.64example/s] \u001b[A\n",
      "Epoch 2 - gen training:  20%|██        | 60/300 [00:00<00:00, 321.78example/s]\u001b[A\n",
      "Epoch 2 - gen training:  40%|████      | 120/300 [00:00<00:00, 334.12example/s]\u001b[A\n",
      "Epoch 2 - gen training:  60%|██████    | 180/300 [00:00<00:00, 344.89example/s]\u001b[A\n",
      "Epoch 2 - gen training:  80%|████████  | 240/300 [00:00<00:00, 353.06example/s]\u001b[A\n",
      "Epoch 2 - gen training: 100%|██████████| 300/300 [00:00<00:00, 358.02example/s]\u001b[A\n",
      "Epoch 2 - gen training:   0%|          | 0/300 [00:00<00:00, 358.02example/s]  \u001b[A\n",
      "\n",
      "Training:   0%|          | 3/3000 [00:06<1:50:15,  2.21s/epoch]\u001b[A\u001b[A\n",
      "Epoch 3 - disc training:   0%|          | 0/300 [00:00<00:00, 358.02example/s]\u001b[A\n",
      "Epoch 3 - disc training:  20%|██        | 60/300 [00:00<00:00, 338.21example/s]\u001b[A\n",
      "Epoch 3 - disc training:  40%|████      | 120/300 [00:00<00:00, 326.78example/s]\u001b[A\n",
      "Epoch 3 - disc training:  60%|██████    | 180/300 [00:00<00:00, 319.11example/s]\u001b[A\n",
      "Epoch 3 - disc training:  80%|████████  | 240/300 [00:00<00:00, 313.54example/s]\u001b[A\n",
      "Epoch 3 - disc training: 100%|██████████| 300/300 [00:00<00:00, 310.42example/s]\u001b[A\n",
      "Epoch 3 - disc training:   0%|          | 0/300 [00:00<00:00, 310.42example/s]  \u001b[A\n",
      "Epoch 3 - gen training:   0%|          | 0/300 [00:00<00:00, 310.42example/s] \u001b[A\n",
      "Epoch 3 - gen training:  20%|██        | 60/300 [00:00<00:00, 325.94example/s]\u001b[A\n",
      "Epoch 3 - gen training:  40%|████      | 120/300 [00:00<00:00, 338.24example/s]\u001b[A\n",
      "Epoch 3 - gen training:  60%|██████    | 180/300 [00:00<00:00, 347.52example/s]\u001b[A\n",
      "Epoch 3 - gen training:  80%|████████  | 240/300 [00:00<00:00, 354.26example/s]\u001b[A\n",
      "Epoch 3 - gen training: 100%|██████████| 300/300 [00:00<00:00, 358.95example/s]\u001b[A\n",
      "Epoch 3 - gen training:   0%|          | 0/300 [00:00<00:00, 358.95example/s]  \u001b[A\n",
      "\n",
      "Training:   0%|          | 4/3000 [00:08<1:44:11,  2.09s/epoch]\u001b[A\u001b[A\n",
      "Epoch 4 - disc training:   0%|          | 0/300 [00:00<00:00, 358.95example/s]\u001b[A\n",
      "Epoch 4 - disc training:  20%|██        | 60/300 [00:00<00:00, 339.18example/s]\u001b[A\n",
      "Epoch 4 - disc training:  40%|████      | 120/300 [00:00<00:00, 327.16example/s]\u001b[A\n",
      "\n",
      "Epoch 4 - disc training:  50%|█████     | 150/300 [00:00<00:00, 276.43example/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-e683e91a203f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0mvalidity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m    164\u001b[0m     output = tf_utils.smart_cond(training,\n\u001b[1;32m    165\u001b[0m                                  \u001b[0mdropped_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m                                  lambda: array_ops.identity(inputs))\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m         pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[1;32m     58\u001b[0m   return smart_module.smart_cond(\n\u001b[0;32m---> 59\u001b[0;31m       pred, true_fn=true_fn, false_fn=false_fn, name=name)\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/framework/smart_cond.py\u001b[0m in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpred_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtrue_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfalse_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/core.py\u001b[0m in \u001b[0;36mdropped_inputs\u001b[0;34m()\u001b[0m\n\u001b[1;32m    160\u001b[0m           \u001b[0mnoise_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_noise_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m           \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m           rate=self.rate)\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     output = tf_utils.smart_cond(training,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 instructions)\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m     doc = _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(x, keep_prob, noise_shape, seed, name, rate)\u001b[0m\n\u001b[1;32m   4227\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You must provide a rate to dropout.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4229\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdropout_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnoise_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mdropout_v2\u001b[0;34m(x, rate, noise_shape, seed, name)\u001b[0m\n\u001b[1;32m   4306\u001b[0m     \u001b[0;31m# and subtract 1.0.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4307\u001b[0m     random_tensor = random_ops.random_uniform(\n\u001b[0;32m-> 4308\u001b[0;31m         noise_shape, seed=seed, dtype=x.dtype)\n\u001b[0m\u001b[1;32m   4309\u001b[0m     \u001b[0mkeep_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4310\u001b[0m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m       \u001b[0mrnd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_random_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnd\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmaxval\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mminval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m     \u001b[0;31m# TODO(b/132092188): C++ shape inference inside functional ops does not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;31m# cross FuncGraph boundaries since that information is only available in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36msub\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m  11070\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m  11071\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sub\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 11072\u001b[0;31m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[1;32m  11073\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  11074\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"../../data/processed_data.json\", \"r\") as f:\n",
    "    data_path = json.load(f)[\"path\"]\n",
    "epochs = 3000\n",
    "warmup_threshold = .70\n",
    "batch_size = 30\n",
    "\n",
    "validity = {\"acc\": [], \"loss\": []}\n",
    "generation = {\"acc\": [], \"loss\": []}\n",
    "\n",
    "size = len(data_path) - len(data_path) % batch_size \n",
    "\n",
    "with tqdm(total=size,\n",
    "        unit='example') as pbar:\n",
    "    \n",
    "    gen = [0, 0]\n",
    "    val = [0, 0]\n",
    "    seed = np.random.normal(size=(16, 100))\n",
    "    \n",
    "    while(val[1] < warmup_threshold):\n",
    "        batch_gen = batches_generator(data_path, batch_size)\n",
    "        \n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        for batch, labels in batch_gen:\n",
    "            noise = np.random.normal(size=(batch_size, 100))\n",
    "            fake_imgs = generator.predict(noise)\n",
    "            fake_labels = np.zeros(batch_size)\n",
    "\n",
    "            x = np.concatenate((np.array(batch), fake_imgs), axis=0)\n",
    "            y = np.concatenate((np.array(labels), fake_labels))\n",
    "\n",
    "            val = discriminator.train_on_batch(x, y)\n",
    "            \n",
    "        print(f\"After warmump validity metrics : {val}\")\n",
    "    \n",
    "    for e in tqdm(range(epochs), desc=\"Training\", unit=\"epoch\"):\n",
    "        pbar.set_description(f\"Epoch {e} - disc training\")\n",
    "        batch_gen = batches_generator(data_path, batch_size)\n",
    "        \n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        for batch, labels in batch_gen:\n",
    "            noise = np.random.normal(size=(batch_size, 100))\n",
    "            fake_imgs = generator.predict(noise)\n",
    "            fake_labels = np.zeros(batch_size)\n",
    "\n",
    "            x = np.concatenate((np.array(batch), fake_imgs), axis=0)\n",
    "            y = np.concatenate((np.array(labels), fake_labels))\n",
    "\n",
    "            val = discriminator.train_on_batch(x, y)\n",
    "            validity[\"loss\"].append(val[0])\n",
    "            validity[\"acc\"].append(val[1])\n",
    "            \n",
    "            pbar.update(len(batch))\n",
    "            \n",
    "        pbar.reset()\n",
    "        pbar.set_description(f\"Epoch {e} - gen training\")\n",
    "        \n",
    "        batch_gen = batches_generator(data_path, batch_size)\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        for batch, labels in batch_gen:\n",
    "            noise = np.random.normal(size=(batch_size, 100))\n",
    "            fake_imgs = generator.predict(noise)\n",
    "            fake_labels = np.zeros(batch_size)\n",
    "\n",
    "            x = np.concatenate((np.array(batch), fake_imgs), axis=0)\n",
    "            y = np.concatenate((np.array(labels), fake_labels))\n",
    "            \n",
    "            gen = combined.train_on_batch(noise, y[batch_size-1:-1])\n",
    "            generation[\"loss\"].append(gen[0])\n",
    "            generation['acc'].append(gen[1])\n",
    "            \n",
    "            pbar.update(len(batch))\n",
    "            \n",
    "        pbar.reset()\n",
    "        \n",
    "        if e % 100 == 0:\n",
    "            see_the_raph_growing(generator, \n",
    "                                 epoch=e, \n",
    "                                 save_path=f\"../../reports/generated_imgs/{e}.png\",\n",
    "                                 noise=seed)\n",
    "        if e % 300 == 0:\n",
    "            discriminator.save(f\"../../models/discriminator-{e}.h5\")\n",
    "            combined.save(f\"../../models/combined-{e}.h5\")\n",
    "            generator.save(f\"../../models/generator-{e}.h5\")\n",
    "    \n",
    "    with open(f\"../../reports/metrics/generation.json\", \"w+\") as f:\n",
    "        json.dump(generation, f)\n",
    "    with open(f\"../../reports/metrics/validity.json\", \"w+\") as f:\n",
    "        json.dump(validity, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_the_raph_growing(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.save(\"../../models/discriminator.h5\")\n",
    "combined.save(\"../../models/combined.h5\")\n",
    "generator.save(\"../../models/generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = np.array(generation)\n",
    "validity = np.array(validity)\n",
    "\n",
    "gen_acc = generation[:,1]\n",
    "disc_acc = validity[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Training history\", size=20, y=0.92)\n",
    "ax = fig.add_axes([0.9, 0.9, 0.9, 0.9])\n",
    "gen_line = ax.plot(np.arange(len(gen_acc)), gen_acc)\n",
    "disc_line = ax.plot(np.arange(len(disc_acc)), disc_acc)\n",
    "fig.legend((gen_line, disc_line), (\"Generative\", \"Discriminative\"), title=\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
