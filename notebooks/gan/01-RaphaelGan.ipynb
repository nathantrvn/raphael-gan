{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genesis of Raphaël\n",
    "\n",
    "Unleashing the power of DCNN to create random Raphaëls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, SpatialDropout2D, Conv2DTranspose, UpSampling2D\n",
    "from tensorflow.keras.layers import Dropout, Input, Dense, Flatten, Reshape, BatchNormalization\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_size):    \n",
    "    generator = Sequential([\n",
    "        # (latent_size)\n",
    "        Input(shape=(latent_size,), name=\"LatentNoise\"),\n",
    "        Dense(16*16*128, activation=\"relu\"),\n",
    "        # (16, 16, 384)\n",
    "        Reshape((16, 16, 128)),\n",
    "        # (32, 32, 192)\n",
    "        UpSampling2D(),\n",
    "        Conv2DTranspose(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "        Conv2DTranspose(64, 3, padding=\"same\", activation=\"relu\"),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        # (64, 64, 96)\n",
    "        UpSampling2D(),\n",
    "        Conv2DTranspose(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        Conv2DTranspose(32, 3, padding=\"same\", activation=\"relu\"),\n",
    "        BatchNormalization(momentum=0.8),\n",
    "        # (128, 128, 3)\n",
    "        UpSampling2D(),\n",
    "        Conv2DTranspose(3, 3, padding=\"same\", activation=\"sigmoid\"),\n",
    "        Conv2DTranspose(3, 3, padding=\"same\", activation=\"sigmoid\"),\n",
    "    ], name=\"generator\")\n",
    "    \n",
    "    return generator\n",
    "\n",
    "def build_discriminator():\n",
    "    \n",
    "    discriminator = Sequential([\n",
    "        # (128, 128, 3)\n",
    "        Input(shape=(128, 128, 3), name=\"InputImages\"),\n",
    "        Conv2D(32, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        Conv2D(32, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(64, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        Conv2D(64, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        MaxPooling2D(),\n",
    "        Dropout(0.2),\n",
    "        \n",
    "        Conv2D(128, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        Conv2D(128, 3, padding=\"same\", kernel_initializer=\"he_normal\"),\n",
    "        LeakyReLU(0.2),\n",
    "        MaxPooling2D(),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dropout(0.2),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.2),\n",
    "        Dense(2, activation=\"softmax\")        \n",
    "    ], name=\"discriminator\")\n",
    "    \n",
    "    return discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = build_generator(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 128, 128, 32)      896       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 32)      9248      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 64, 64, 64)        36928     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 128)       73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 32, 32, 128)       147584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               4194432   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 4,481,698\n",
      "Trainable params: 4,481,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32768)             3309568   \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d (UpSampling2D) (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 64, 64, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 32)        128       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 128, 128, 3)       867       \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 128, 128, 3)       84        \n",
      "=================================================================\n",
      "Total params: 3,449,335\n",
      "Trainable params: 3,449,143\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_combined(discriminator, generator, latent_size):\n",
    "    noise = Input(shape=(latent_size, ), name=\"noise\")\n",
    "    fake_raph = generator(noise)\n",
    "    discriminator.trainable = False\n",
    "    validation = discriminator(fake_raph)\n",
    "    return Model(noise, validation, name=\"combined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = build_combined(discriminator, generator, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"combined\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "noise (InputLayer)           [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "generator (Sequential)       (None, 128, 128, 3)       3449335   \n",
      "_________________________________________________________________\n",
      "discriminator (Sequential)   (None, 2)                 4481698   \n",
      "=================================================================\n",
      "Total params: 7,931,033\n",
      "Trainable params: 3,449,143\n",
      "Non-trainable params: 4,481,890\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "combined.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.0002, decay=1e-7)\n",
    "\n",
    "discriminator.trainable = True\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "\n",
    "combined.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = np.random.normal(size=(1, 100))\n",
    "rand_img = generator.predict(noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f43246e6cf8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(rand_img.reshape((128, 128, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batches_generator(data_path, batch_size):\n",
    "    indexes = np.random.choice(len(data_path), len(data_path), replace=False)\n",
    "    for batch_index in range(len(data_path) // batch_size):\n",
    "        index = indexes[batch_index*batch_size:batch_index*batch_size + batch_size]\n",
    "        batch = []\n",
    "        labels = np.ones(batch_size)\n",
    "        for i in index:\n",
    "            batch.append(np.load(data_path[i]))\n",
    "        yield np.array(batch), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def see_the_raph_growing(generator, epoch=None, save_path=None, size=(4, 4), noise=None):\n",
    "    if noise is None:\n",
    "        noise = np.random.normal(size=(size[0]*size[1], 100))\n",
    "    fake_imgs = generator.predict(noise)\n",
    "    fig = plt.figure(figsize=(size[0]*4, size[1]*3))\n",
    "    if not(epoch is None):\n",
    "        fig.suptitle(f\"Epoch {epoch}\", size=20, y=0.92)\n",
    "    for i, img in enumerate(fake_imgs):\n",
    "        axes = fig.add_subplot(size[0], size[1], i+1)\n",
    "        axes.set_axis_off()\n",
    "        axes.imshow(img)\n",
    "    if not(save_path is None):\n",
    "        fig.savefig(save_path)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/300 [00:00<?, ?example/s]\n",
      "Training:   0%|          | 0/3000 [00:04<?, ?epoch/s]03<00:33,  8.13example/s]\n",
      "Epoch 0 - disc training:  10%|█         | 30/300 [00:04<00:39,  6.79example/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_FallbackException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;34m\"explicit_paddings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"data_format\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \"dilations\", dilations)\n\u001b[0m\u001b[1;32m   1025\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31m_FallbackException\u001b[0m: Expecting int64_t value for attr strides, got numpy.int32",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5eb8b1968faa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0mvalidity\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[1;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[1;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[1;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[1;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[1;32m    312\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    250\u001b[0m               \u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_loss_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m               \u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m               training=training))\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         raise ValueError('The model cannot be run '\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_eager.py\u001b[0m in \u001b[0;36m_model_loss\u001b[0;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    254\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[0;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m   1132\u001b[0m           call_from_convolution=False)\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m     \u001b[0;31m# copybara:strip_end\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[0;31m# copybara:insert return self.conv_op(inp, filter)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=redefined-builtin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inp, filter)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         name=self.name)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\u001b[0m\n\u001b[1;32m   2008\u001b[0m                            \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m                            \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2010\u001b[0;31m                            name=name)\n\u001b[0m\u001b[1;32m   2011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2012\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m             \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1031\u001b[0;31m             data_format=data_format, dilations=dilations, name=name, ctx=_ctx)\n\u001b[0m\u001b[1;32m   1032\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d_eager_fallback\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name, ctx)\u001b[0m\n\u001b[1;32m   1128\u001b[0m   explicit_paddings, \"data_format\", data_format, \"dilations\", dilations)\n\u001b[1;32m   1129\u001b[0m   _result = _execute.execute(b\"Conv2D\", 1, inputs=_inputs_flat, attrs=_attrs,\n\u001b[0;32m-> 1130\u001b[0;31m                              ctx=_ctx, name=name)\n\u001b[0m\u001b[1;32m   1131\u001b[0m   _execute.record_gradient(\n\u001b[1;32m   1132\u001b[0m       \"Conv2D\", _inputs_flat, _attrs, _result, name)\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with open(\"../../data/processed_data.json\", \"r\") as f:\n",
    "    data_path = json.load(f)[\"path\"]\n",
    "epochs = 3000\n",
    "batch_size = 30\n",
    "\n",
    "validity = []\n",
    "generation = []\n",
    "\n",
    "size = len(data_path) - len(data_path) % batch_size \n",
    "\n",
    "with tqdm(total=size,\n",
    "        unit='example') as pbar:\n",
    "    \n",
    "    gen = [0, 0]\n",
    "    val = [0, 0]\n",
    "    seed = np.random.normal(size=(16, 100))\n",
    "    \n",
    "    for e in tqdm(range(epochs), desc=\"Training\", unit=\"epoch\"):\n",
    "        pbar.set_description(f\"Epoch {e} - disc training\")\n",
    "        batch_gen = batches_generator(data_path, batch_size)\n",
    "        \n",
    "        discriminator.trainable = True\n",
    "        \n",
    "        for batch, labels in batch_gen:\n",
    "            noise = np.random.normal(size=(batch_size, 100))\n",
    "            fake_imgs = generator.predict(noise)\n",
    "            fake_labels = np.zeros(batch_size)\n",
    "\n",
    "            x = np.concatenate((np.array(batch), fake_imgs), axis=0)\n",
    "            y = np.concatenate((np.array(labels), fake_labels))\n",
    "\n",
    "            y = keras.utils.to_categorical(y)\n",
    "\n",
    "            val = discriminator.train_on_batch(x, y)\n",
    "            validity.append(val)\n",
    "            \n",
    "            pbar.update(len(batch))\n",
    "            \n",
    "        pbar.reset()\n",
    "        pbar.set_description(f\"Epoch {e} - gen training\")\n",
    "        \n",
    "        batch_gen = batches_generator(data_path, batch_size)\n",
    "        discriminator.trainable = False\n",
    "        \n",
    "        for batch, labels in batch_gen:\n",
    "            noise = np.random.normal(size=(batch_size, 100))\n",
    "            fake_imgs = generator.predict(noise)\n",
    "            fake_labels = np.zeros(batch_size)\n",
    "\n",
    "            x = np.concatenate((np.array(batch), fake_imgs), axis=0)\n",
    "            y = np.concatenate((np.array(labels), fake_labels))\n",
    "\n",
    "            y = keras.utils.to_categorical(y)\n",
    "            \n",
    "            gen = combined.train_on_batch(noise, y[batch_size-1:-1, :])\n",
    "            generation.append(gen)\n",
    "            \n",
    "            pbar.update(len(batch))\n",
    "            \n",
    "        pbar.reset()\n",
    "        \n",
    "        if e % 100 == 0:\n",
    "            see_the_raph_growing(generator, \n",
    "                                 epoch=e, \n",
    "                                 save_path=f\"../../reports/generated_imgs/{e}.png\",\n",
    "                                 noise=seed)\n",
    "        if e % 300 == 0:\n",
    "            discriminator.save(f\"../../models/discriminator-{e}.h5\")\n",
    "            combined.save(f\"../../models/combined-{e}.h5\")\n",
    "            generator.save(f\"../../models/generator-{e}.h5\")\n",
    "    \n",
    "    with open(f\"../../reports/metrics/generation.json\", \"w+\") as f:\n",
    "        json.dump(generation, f)\n",
    "    with open(f\"../../reports/metrics/validity.json\", \"w+\") as f:\n",
    "        json.dump(validity, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "see_the_raph_growing(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.save(\"../../models/discriminator.h5\")\n",
    "combined.save(\"../../models/combined.h5\")\n",
    "generator.save(\"../../models/generator.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation = np.array(generation)\n",
    "validity = np.array(validity)\n",
    "\n",
    "gen_acc = generation[:,1]\n",
    "disc_acc = validity[:,1]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Training history\", size=20, y=0.92)\n",
    "ax = fig.add_axes([0.9, 0.9, 0.9, 0.9])\n",
    "gen_line = ax.plot(np.arange(len(gen_acc)), gen_acc)\n",
    "disc_line = ax.plot(np.arange(len(disc_acc)), disc_acc)\n",
    "fig.legend((gen_line, disc_line), (\"Generative\", \"Discriminative\"), title=\"Accuracy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
